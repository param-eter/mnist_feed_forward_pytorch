{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hand written digit identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training data - The transform turns the image into a tensor\n",
    "train_dataset = dsets.MNIST(root = './data', train = True, transform = transforms.ToTensor(), download = True)\n",
    "#Test dataset\n",
    "test_dataset = dsets.MNIST(root = './data', train = False, transform = transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check how big training the data is\n",
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check how big test the data is\n",
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Look at one of the items in the training data and get its type\n",
    "type(train_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "#It's a tuple so we want to extract the 2 items\n",
    "img_0, label_0 = train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Ge the size of the image\n",
    "img_0.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "(0 ,.,.) = \n",
       "\n",
       "Columns 0 to 8 \n",
       "   0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.1176\n",
       "  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.1922  0.9333\n",
       "  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0706  0.8588\n",
       "  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.3137\n",
       "  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0902\n",
       "  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0706  0.6706  0.8588\n",
       "  0.0000  0.0000  0.0000  0.0000  0.2157  0.6745  0.8863  0.9922  0.9922\n",
       "  0.0000  0.0000  0.0000  0.0000  0.5333  0.9922  0.9922  0.9922  0.8314\n",
       "  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "\n",
       "Columns 9 to 17 \n",
       "   0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "  0.0000  0.0000  0.0000  0.0118  0.0706  0.0706  0.0706  0.4941  0.5333\n",
       "  0.1412  0.3686  0.6039  0.6667  0.9922  0.9922  0.9922  0.9922  0.9922\n",
       "  0.9922  0.9922  0.9922  0.9922  0.9922  0.9922  0.9922  0.9922  0.9843\n",
       "  0.9922  0.9922  0.9922  0.9922  0.9922  0.7765  0.7137  0.9686  0.9451\n",
       "  0.6118  0.4196  0.9922  0.9922  0.8039  0.0431  0.0000  0.1686  0.6039\n",
       "  0.0549  0.0039  0.6039  0.9922  0.3529  0.0000  0.0000  0.0000  0.0000\n",
       "  0.0000  0.0000  0.5451  0.9922  0.7451  0.0078  0.0000  0.0000  0.0000\n",
       "  0.0000  0.0000  0.0431  0.7451  0.9922  0.2745  0.0000  0.0000  0.0000\n",
       "  0.0000  0.0000  0.0000  0.1373  0.9451  0.8824  0.6275  0.4235  0.0039\n",
       "  0.0000  0.0000  0.0000  0.0000  0.3176  0.9412  0.9922  0.9922  0.4667\n",
       "  0.0000  0.0000  0.0000  0.0000  0.0000  0.1765  0.7294  0.9922  0.9922\n",
       "  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0627  0.3647  0.9882\n",
       "  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.9765\n",
       "  0.0000  0.0000  0.0000  0.0000  0.0000  0.1804  0.5098  0.7176  0.9922\n",
       "  0.0000  0.0000  0.0000  0.1529  0.5804  0.8980  0.9922  0.9922  0.9922\n",
       "  0.0000  0.0941  0.4471  0.8667  0.9922  0.9922  0.9922  0.9922  0.7882\n",
       "  0.2588  0.8353  0.9922  0.9922  0.9922  0.9922  0.7765  0.3176  0.0078\n",
       "  0.9922  0.9922  0.9922  0.9922  0.7647  0.3137  0.0353  0.0000  0.0000\n",
       "  0.9922  0.9922  0.9569  0.5216  0.0431  0.0000  0.0000  0.0000  0.0000\n",
       "  0.5294  0.5176  0.0627  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "\n",
       "Columns 18 to 26 \n",
       "   0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "  0.6863  0.1020  0.6510  1.0000  0.9686  0.4980  0.0000  0.0000  0.0000\n",
       "  0.8824  0.6745  0.9922  0.9490  0.7647  0.2510  0.0000  0.0000  0.0000\n",
       "  0.3647  0.3216  0.3216  0.2196  0.1529  0.0000  0.0000  0.0000  0.0000\n",
       "  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "  0.0980  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "  0.5882  0.1059  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "  0.9922  0.7333  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "  0.9922  0.9765  0.2510  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "  0.9922  0.8118  0.0078  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "  0.9804  0.7137  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "  0.3059  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "\n",
       "Columns 27 to 27 \n",
       "   0.0000\n",
       "  0.0000\n",
       "  0.0000\n",
       "  0.0000\n",
       "  0.0000\n",
       "  0.0000\n",
       "  0.0000\n",
       "  0.0000\n",
       "  0.0000\n",
       "  0.0000\n",
       "  0.0000\n",
       "  0.0000\n",
       "  0.0000\n",
       "  0.0000\n",
       "  0.0000\n",
       "  0.0000\n",
       "  0.0000\n",
       "  0.0000\n",
       "  0.0000\n",
       "  0.0000\n",
       "  0.0000\n",
       "  0.0000\n",
       "  0.0000\n",
       "  0.0000\n",
       "  0.0000\n",
       "  0.0000\n",
       "  0.0000\n",
       "  0.0000\n",
       "[torch.FloatTensor of size 1x28x28]"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#View the image (actually its tensor representation)\n",
    "img_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#View the label\n",
    "label_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see above that our training dataset consists of 60,000 tuples.\n",
    "Each tuple contains a tensor representation of a handwritten image and a label telling us what number from 0-9 it represents.\n",
    "\n",
    "The test data set has the same structure but is smaller at 10,000 tuples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set some model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4200"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Batch size - the number of observations to use before updating the parameters\n",
    "batch_size = 100\n",
    "#Epochs - the number of complete passes through the data (needs to be an int)\n",
    "num_epochs = 7\n",
    "#Number of iterations - The number of batches needed in total\n",
    "n_iters = num_epochs*(len(train_dataset)/batch_size)\n",
    "n_iters = int(n_iters)\n",
    "n_iters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make datasets iterable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The datasets need to be iterable so we use a torch data loader\n",
    "train_loader = torch.utils.data.DataLoader(dataset = train_dataset, batch_size = batch_size, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset = test_dataset, batch_size = batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a feed forward neural network with 2 non linear functions.\n",
    "We don't add a final softmax layer as it's provided by our loss class.\n",
    "\n",
    "The init section is where we build the model layer by layer.\n",
    "The forward method is where we define how the data moves through the layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForwardNeuralNetModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_dim):\n",
    "        super(FeedForwardNeuralNetModel, self).__init__()\n",
    "        #Linear function\n",
    "        self.fcl = nn.Linear(input_dim, hidden_dim)\n",
    "        #Non linearity\n",
    "        self.relu1 = nn.ReLU()\n",
    "        #Linear function\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        #Non linearity 2\n",
    "        self.relu2 = nn.ReLU()\n",
    "        #Linear function (readout)\n",
    "        self.fc3 = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #Linear function\n",
    "        out = self.fcl(x)\n",
    "        #Non linear function\n",
    "        out = self.relu1(out)\n",
    "        #Linear function\n",
    "        out = self.fc2(out)\n",
    "        #Non linear function\n",
    "        out = self.relu2(out)\n",
    "        #Linear function\n",
    "        out = self.fc3(out)\n",
    "        #Return final values\n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "#These parameters are required to instantiate your model\n",
    "#Size of the input data\n",
    "input_dim = 28*28\n",
    "#Number of hidden neurons (can be adjusted)\n",
    "hidden_dim = 350\n",
    "#Number of output values (digits 0-9)\n",
    "output_dim = 10\n",
    "\n",
    "\n",
    "#Create model using the parameters above    \n",
    "model = FeedForwardNeuralNetModel(input_dim, hidden_dim, output_dim)\n",
    "\n",
    "#If cuda is available, move the model to the GPU for increased performance\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate loss class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is a multi class problem so we're using cross entropy (also known as log loss)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate optimiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the learning rate (this can be adjusted)\n",
    "learning_rate = 0.1\n",
    "\n",
    "#Create a pytorch optimiser\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model parameters in depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object Module.parameters at 0x7f7e9b447570>\n",
      "torch.Size([350, 784])\n",
      "torch.Size([350])\n",
      "torch.Size([350, 350])\n",
      "torch.Size([350])\n",
      "torch.Size([10, 350])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "#Have a look at the model parameters\n",
    "print(model.parameters())\n",
    "\n",
    "#Above not useful, need to pass through a list\n",
    "#Linear layer and bias (essentialy the intercept)\n",
    "print(list(model.parameters())[0].size())\n",
    "print(list(model.parameters())[1].size())\n",
    "\n",
    "#Second linear layer and bias\n",
    "print(list(model.parameters())[2].size())\n",
    "print(list(model.parameters())[3].size())\n",
    "\n",
    "#Third linear layer and bias\n",
    "print(list(model.parameters())[4].size())\n",
    "print(list(model.parameters())[5].size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1. Iteration: 200. Loss: 0.4716443717479706. Accuracy 88.83\n",
      "Epoch: 1. Iteration: 400. Loss: 0.3200089633464813. Accuracy 91.06\n",
      "Epoch: 1. Iteration: 600. Loss: 0.3572040796279907. Accuracy 92.41\n",
      "Epoch: 2. Iteration: 800. Loss: 0.21023090183734894. Accuracy 93.33\n",
      "Epoch: 2. Iteration: 1000. Loss: 0.1356976181268692. Accuracy 93.84\n",
      "Epoch: 2. Iteration: 1200. Loss: 0.24825680255889893. Accuracy 94.44\n",
      "Epoch: 3. Iteration: 1400. Loss: 0.12240671366453171. Accuracy 95.16\n",
      "Epoch: 3. Iteration: 1600. Loss: 0.16904540359973907. Accuracy 95.63\n",
      "Epoch: 3. Iteration: 1800. Loss: 0.19754821062088013. Accuracy 95.89\n",
      "Epoch: 4. Iteration: 2000. Loss: 0.23999981582164764. Accuracy 96.17\n",
      "Epoch: 4. Iteration: 2200. Loss: 0.07208829373121262. Accuracy 96.39\n",
      "Epoch: 4. Iteration: 2400. Loss: 0.06589969247579575. Accuracy 96.61\n",
      "Epoch: 5. Iteration: 2600. Loss: 0.060507114976644516. Accuracy 96.67\n",
      "Epoch: 5. Iteration: 2800. Loss: 0.1321420520544052. Accuracy 96.9\n",
      "Epoch: 5. Iteration: 3000. Loss: 0.0733414813876152. Accuracy 97.07\n",
      "Epoch: 6. Iteration: 3200. Loss: 0.19604964554309845. Accuracy 97.0\n",
      "Epoch: 6. Iteration: 3400. Loss: 0.06858015060424805. Accuracy 97.17\n",
      "Epoch: 6. Iteration: 3600. Loss: 0.07578126341104507. Accuracy 97.24\n",
      "Epoch: 7. Iteration: 3800. Loss: 0.04680134356021881. Accuracy 97.3\n",
      "Epoch: 7. Iteration: 4000. Loss: 0.06960532069206238. Accuracy 97.29\n",
      "Epoch: 7. Iteration: 4200. Loss: 0.03355388715863228. Accuracy 97.55\n"
     ]
    }
   ],
   "source": [
    "iter = 0\n",
    "\n",
    "#Cycle through all of the epochs\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    #Iterate through the batches in the train loader\n",
    "    for i, (images,labels) in enumerate(train_loader):\n",
    "        \n",
    "        #Load images and variables as labels. If the GPU is available, move them there\n",
    "        if torch.cuda.is_available():\n",
    "            images  = Variable(images.view(-1,28*28).cuda())\n",
    "            labels = Variable(labels.cuda())\n",
    "        else:    \n",
    "            images  = Variable(images.view(-1,28*28))\n",
    "            labels = Variable(labels)\n",
    "        \n",
    "        \n",
    "        \n",
    "        #Clear gradients w.r.t parameters\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        #Forward pass to get outputs/logits\n",
    "        outputs = model(images)\n",
    "        \n",
    "        #Calculate loss: cross entropy\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        #Get gradients w.r.t parameters\n",
    "        loss.backward()\n",
    "        \n",
    "        #Update parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        iter += 1\n",
    "        \n",
    "        if iter % 200 == 0:\n",
    "            #Calculate accuracy\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            #Iterate through test dataset\n",
    "            for images, labels in test_loader:\n",
    "                #Load images and labels to torch variables\n",
    "                if torch.cuda.is_available():                \n",
    "                    images = Variable(images.view(-1,28*28).cuda())\n",
    "                else:\n",
    "                    images = Variable(images.view(-1,28*28))\n",
    "                \n",
    "                #Forward pass only\n",
    "                outputs = model(images)\n",
    "                \n",
    "                #Get predictions using the maximum value\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                \n",
    "                #Total number of labels\n",
    "                total += labels.size(0)\n",
    "                \n",
    "                #Total correct predictions - needs to be moved back to the CPU for the sum function to work\n",
    "                if torch.cuda.is_available():\n",
    "                    correct += (predicted.cpu() == labels.cpu()).sum()\n",
    "                else:\n",
    "                    correct += (predicted == labels).sum()\n",
    "                \n",
    "            accuracy = 100 * correct / total  \n",
    "            \n",
    "            #Print loss\n",
    "            print('Epoch: {}. Iteration: {}. Loss: {}. Accuracy {}'.format(epoch + 1 ,iter, loss.data[0], accuracy))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model above gets us an accuracy of 97.56% on the test data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
